{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_cloud_of_tweet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fffw2/colaboratory/blob/main/word_cloud_of_tweet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRs24INrumu-"
      },
      "source": [
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!pip install janome\n",
        "!pip install wordcloud\n",
        "import datetime as dt\n",
        "import io\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_IOuH0HssLo"
      },
      "source": [
        "# tweet.js (+ あれば tweet-part1.js ) をアップロード\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1jwMvptoJh_"
      },
      "source": [
        "# tweet.js を dataframe に変換\n",
        "tweet_data_part0 = pd.read_json(io.StringIO(uploaded['tweet.js'].decode('utf-8').replace(\"window.YTD.tweet.part0 = \",\"\")))\n",
        "df = pd.json_normalize(tweet_data_part0.to_dict('records'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoRg8Mqff2JJ"
      },
      "source": [
        "# ( tweet-part1.js があるときだけ実行 )\n",
        "# tweet-part1.js を dataframe に変換してマージ\n",
        "# tweet_data_part1 = pd.read_json(io.StringIO(uploaded['tweet-part1.js'].decode('utf-8').replace(\"window.YTD.tweet.part1 = \",\"\")))\n",
        "# df1 = pd.json_normalize(tweet_data_part1.to_dict('records'))\n",
        "# df = pd.concat([df, df1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWhp3RMck33Z"
      },
      "source": [
        "# 日付ごとに集計してグラフを生成\n",
        "df['tweet.created_at'] = pd.to_datetime(df['tweet.created_at'])\n",
        "df['date'] = df['tweet.created_at'].dt.date\n",
        "tweets_cnt = df.groupby('date').size()\n",
        "tweets_cnt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UfuSS6Ymygu"
      },
      "source": [
        "# テキストの前処理を定義\n",
        "import re\n",
        "def normalize_text(text):\n",
        "    text = re.sub(r'#.*', \"\", text)\n",
        "    text = re.sub(r'&gt', \"\", text)\n",
        "    text = re.sub(r'\\n', \"\", text)\n",
        "    text = re.sub(r'https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', \"\", text)\n",
        "    text = re.sub('よう', \"\", text)\n",
        "    text = re.sub('これ', \"\", text)\n",
        "    text = re.sub('こと', \"\", text)\n",
        "    text = re.sub('さん', \"\", text)\n",
        "    text = re.sub('もの', \"\", text)\n",
        "    text = re.sub('とき', \"\", text)\n",
        "    text = re.sub('そう', \"\", text)\n",
        "    text = re.sub('ため', \"\", text)\n",
        "    text = re.sub('はず', \"\", text)\n",
        "    text = re.sub('ほう', \"\", text)\n",
        "    text = re.sub('ところ', \"\", text)\n",
        "    text = re.sub('みたい', \"\", text)\n",
        "    text = re.sub('あたり', \"\", text)\n",
        "    text = re.sub('くん', \"\", text)\n",
        "    text = re.sub('たち', \"\", text)\n",
        "    text = re.sub('ぶり', \"\", text)\n",
        "    text = re.sub('ちゃん', \"\", text)\n",
        "    text = re.sub('あと', \"\", text)\n",
        "    text = re.sub('うち', \"\", text)\n",
        "    text = re.sub('ここ', \"\", text)\n",
        "    text = re.sub('それ', \"\", text)\n",
        "    text = re.sub('わけ', \"\", text)\n",
        "    text = re.sub('あれ', \"\", text)\n",
        "    text = re.sub('もん', \"\", text)\n",
        "    text = re.sub('たん', \"\", text)\n",
        "    text = re.sub('まま', \"\", text)\n",
        "    text = re.sub('なん', \"\", text)\n",
        "    text = re.sub('せい', \"\", text)\n",
        "    text = re.sub('がち', \"\", text)\n",
        "    text = re.sub('うろ', \"\", text)\n",
        "    text = re.sub('今日', \"\", text)\n",
        "    text = re.sub('昨日', \"\", text)\n",
        "    text = re.sub('明日', \"\", text)\n",
        "    text = re.sub('時間', \"\", text)\n",
        "    text = re.sub('今年', \"\", text)\n",
        "    text = re.sub('去年', \"\", text)\n",
        "    text = re.sub('昨年', \"\", text)\n",
        "    text = re.sub('来年', \"\", text)\n",
        "    text = re.sub('fffw', \"\", text)\n",
        "    text = re.sub(r'^@.*', \"\", text)\n",
        "    text = re.sub(r'^RT .*', \"\", text)\n",
        "    text = re.sub('RT', \"\", text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iids4FypIOG7"
      },
      "source": [
        "日付範囲を変更したらここから下を再処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFxgiC8C-oa"
      },
      "source": [
        "# 日付範囲を指定してテキストのリストを生成\n",
        "start_date = dt.date(2020,1,1)\n",
        "end_date = dt.date(2020,12,31)\n",
        "text_list = df[(start_date <= df['date']) & (df['date'] <= end_date)]['tweet.full_text'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItaBZaO3F_Ea"
      },
      "source": [
        "# テキストのリストに前処理を適用\n",
        "normalized_text_list = [normalize_text(t) for t in text_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kc8VhpS7AdJ"
      },
      "source": [
        "# テキストのリストから単語のリストを生成\n",
        "from janome.tokenizer import Tokenizer\n",
        "t = Tokenizer()\n",
        "word_list = []\n",
        "for text in normalized_text_list:\n",
        "    tokens = t.tokenize(text)\n",
        "    for token in tokens:\n",
        "        if token.part_of_speech.split(',')[0] == '名詞':    #名詞のみを抽出\n",
        "            word_list.append(token.base_form)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vEtxUcR43KI"
      },
      "source": [
        "# 単語を頻出順に表示\n",
        "from collections import Counter\n",
        "filtered_word_list = [w for w in word_list if len(w)>1]   #1文字の単語を除去\n",
        "common_word_list = Counter(filtered_word_list).most_common()\n",
        "print(common_word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knS5zBfotY-a"
      },
      "source": [
        "# WordCloud を生成\n",
        "from wordcloud import WordCloud\n",
        "fpath = '/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf'\n",
        "words = ' '.join(word_list)   #単語リストを半角スペース区切りの文字列に変換\n",
        "wordcloud = WordCloud(background_color=\"white\", font_path=fpath, width=900, height=500, collocations = False).generate(words)\n",
        "plt.figure(figsize=(15,12))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18V4ueiERNJi"
      },
      "source": [
        "# 参考サイト\n",
        "# https://karaage.hatenadiary.jp/entry/2018/03/21/073000\n",
        "# https://www.hitowaft.work/entry/2020/05/11/203550\n",
        "# https://qiita.com/kbs/items/33b3dd6dae15f7b20b9e\n",
        "# https://limited-exp-bug.hatenablog.com/entry/2020/05/23/205957"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}